# ä»»åŠ¡é˜Ÿåˆ—è®¾è®¡

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜ AI-NoteBook ç³»ç»Ÿçš„å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—è®¾è®¡ã€‚

## æ¦‚è¿°

AI-NoteBook ä½¿ç”¨ **BullMQ + Redis** æ„å»ºé«˜æ€§èƒ½ã€å¯é çš„ä»»åŠ¡é˜Ÿåˆ—ç³»ç»Ÿï¼Œç”¨äºå¤„ç†è€—æ—¶çš„ AI æ–‡ç« è§£æä»»åŠ¡ã€‚

### æ ¸å¿ƒç‰¹æ€§

- âš¡ **å¼‚æ­¥å¤„ç†**ï¼šé¿å…é˜»å¡ä¸»çº¿ç¨‹ï¼Œæå‡APIå“åº”é€Ÿåº¦
- ğŸ”„ **è‡ªåŠ¨é‡è¯•**ï¼šå¤±è´¥ä»»åŠ¡è‡ªåŠ¨é‡è¯•ï¼Œæé«˜æˆåŠŸç‡
- ğŸ“Š **è¿›åº¦è¿½è¸ª**ï¼šå®æ—¶æ¨é€ä»»åŠ¡è¿›åº¦ç»™å‰ç«¯
- â° **å»¶è¿Ÿè°ƒåº¦**ï¼šæ”¯æŒå®šæ—¶ä»»åŠ¡å’Œå»¶è¿Ÿæ‰§è¡Œ
- ğŸ¯ **ä¼˜å…ˆçº§é˜Ÿåˆ—**ï¼šVIPä¼šå‘˜ä»»åŠ¡ä¼˜å…ˆå¤„ç†
- ğŸ” **å¯è§†åŒ–ç›‘æ§**ï¼šBull Boardé¢æ¿å®æ—¶ç›‘æ§é˜Ÿåˆ—çŠ¶æ€

## æ¶æ„è®¾è®¡

### æ•´ä½“æ¶æ„

```mermaid
graph TB
    A[APIæœåŠ¡] -->|æ·»åŠ ä»»åŠ¡| B[åˆ†æé˜Ÿåˆ— Queue]
    B -->|Redis| C[ä»»åŠ¡å­˜å‚¨]
    D[Worker 1] -->|æ‹‰å–ä»»åŠ¡| C
    E[Worker 2] -->|æ‹‰å–ä»»åŠ¡| C
    F[Worker 3] -->|æ‹‰å–ä»»åŠ¡| C

    D -->|å¤„ç†| G[AIæœåŠ¡]
    E -->|å¤„ç†| G
    F -->|å¤„ç†| G

    G -->|æœç´¢| H[æœç´¢æœåŠ¡]
    G -->|ä¿å­˜ç»“æœ| I[PostgreSQL]

    D -->|æ›´æ–°è¿›åº¦| J[WebSocket]
    E -->|æ›´æ–°è¿›åº¦| J
    F -->|æ›´æ–°è¿›åº¦| J

    J -->|æ¨é€| K[å‰ç«¯]

    L[Bull Board] -->|ç›‘æ§| B
    L -->|ç›‘æ§| C

    style B fill:#4ecdc4
    style C fill:#95a5a6
    style G fill:#3498db
    style J fill:#e74c3c
```

### æ•°æ®æµ

```mermaid
sequenceDiagram
    participant Client as å®¢æˆ·ç«¯
    participant API as APIæœåŠ¡
    participant Queue as ä»»åŠ¡é˜Ÿåˆ—
    participant Worker as Worker
    participant AI as AIæœåŠ¡
    participant DB as æ•°æ®åº“
    participant WS as WebSocket

    Client->>API: POST /api/analysis
    API->>API: éªŒè¯ä¼šå‘˜é¢åº¦
    API->>Queue: æ·»åŠ è§£æä»»åŠ¡
    Queue-->>API: è¿”å›Job ID
    API-->>Client: è¿”å›taskId + çŠ¶æ€=PROCESSING

    Queue->>Worker: åˆ†é…ä»»åŠ¡
    Worker->>AI: æ˜“è¯»æ€§è¯„åˆ†
    AI-->>Worker: è¿”å›è¯„åˆ†
    Worker->>WS: æ›´æ–°è¿›åº¦ 30%

    Worker->>AI: å†…å®¹æç‚¼
    AI-->>Worker: è¿”å›æç‚¼ç»“æœ
    Worker->>WS: æ›´æ–°è¿›åº¦ 60%

    alt éœ€è¦æ‰©å±•
        Worker->>AI: åˆ†ææ‰©å±•ç‚¹
        AI-->>Worker: è¿”å›æ‰©å±•å…³é”®è¯
        Worker->>Worker: æœç´¢ç›¸å…³èµ„æ–™
        Worker->>AI: åŸºäºæœç´¢æ‰©å±•
        AI-->>Worker: è¿”å›æ‰©å±•å†…å®¹
    end

    Worker->>DB: ä¿å­˜ç»“æœ
    Worker->>WS: æ›´æ–°è¿›åº¦ 100% + ç»“æœ
    WS->>Client: æ¨é€å®Œæˆé€šçŸ¥

    Client->>API: GET /api/analysis/:id
    API->>DB: æŸ¥è¯¢ç»“æœ
    API-->>Client: è¿”å›å®Œæ•´æ•°æ®
```

## ä¸€ã€é˜Ÿåˆ—è®¾è®¡

### 1.1 é˜Ÿåˆ—å®šä¹‰

```typescript
// src/modules/analysis/queues/analysis.queue.ts
import { Queue, QueueOptions } from 'bullmq'
import { InjectRedis } from '@nestjs-modules/ioredis'
import Redis from 'ioredis'

export interface AnalyzeJobData {
  userId: string
  analysisId: string
  content: string
  title?: string
  enableExpansion: boolean
  priority: number // 1-10, 10ä¸ºæœ€é«˜ä¼˜å…ˆçº§
}

export const ANALYSIS_QUEUE_NAME = 'analysis'

export class AnalysisQueue {
  private queue: Queue<AnalyzeJobData>

  constructor(@InjectRedis() private redis: Redis) {
    const options: QueueOptions = {
      connection: {
        host: process.env.REDIS_HOST,
        port: parseInt(process.env.REDIS_PORT),
        password: process.env.REDIS_PASSWORD
      },
      defaultJobOptions: {
        attempts: 3, // å¤±è´¥é‡è¯•3æ¬¡
        backoff: {
          type: 'exponential',
          delay: 2000 // åˆå§‹å»¶è¿Ÿ2ç§’
        },
        removeOnComplete: {
          count: 1000, // ä¿ç•™æœ€è¿‘1000ä¸ªå®Œæˆä»»åŠ¡
          age: 7 * 24 * 3600 // æˆ–7å¤©å†…
        },
        removeOnFail: {
          count: 5000, // ä¿ç•™æœ€è¿‘5000ä¸ªå¤±è´¥ä»»åŠ¡
          age: 30 * 24 * 3600 // æˆ–30å¤©å†…
        }
      }
    }

    this.queue = new Queue(ANALYSIS_QUEUE_NAME, options)
  }

  async addAnalyzeJob(data: AnalyzeJobData) {
    return this.queue.add('analyze-article', data, {
      jobId: data.analysisId, // ä½¿ç”¨analysisIdä½œä¸ºJobIdï¼Œå¹‚ç­‰æ€§
      priority: data.priority
    })
  }

  async getJob(jobId: string) {
    return this.queue.getJob(jobId)
  }

  async getJobState(jobId: string) {
    return this.queue.getJobState(jobId)
  }

  // è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯
  async getQueueStats() {
    const [waiting, active, completed, failed, delayed] = await Promise.all([
      this.queue.getWaitingCount(),
      this.queue.getActiveCount(),
      this.queue.getCompletedCount(),
      this.queue.getFailedCount(),
      this.queue.getDelayedCount()
    ])

    return {
      waiting,
      active,
      completed,
      failed,
      delayed,
      total: waiting + active + completed + failed + delayed
    }
  }

  // æ¸…ç†é˜Ÿåˆ—
  async clean() {
    await this.queue.clean(7 * 24 * 3600, 1000, 'completed')
    await this.queue.clean(30 * 24 * 3600, 5000, 'failed')
  }
}
```

### 1.2 é˜Ÿåˆ—é…ç½®

```typescript
// src/modules/analysis/queues/queue.config.ts
export const QUEUE_CONFIG = {
  // å¹¶å‘é…ç½®
  concurrency: {
    FREE: 1,      // å…è´¹ç”¨æˆ·ï¼š1ä¸ªå¹¶å‘ä»»åŠ¡
    PRO: 5,       // ä¸“ä¸šç‰ˆï¼š5ä¸ªå¹¶å‘ä»»åŠ¡
    ENTERPRISE: 20 // ä¼ä¸šç‰ˆï¼š20ä¸ªå¹¶å‘ä»»åŠ¡
  },

  // ä¼˜å…ˆçº§é…ç½®
  priority: {
    ENTERPRISE: 10, // ä¼ä¸šç‰ˆä¼˜å…ˆçº§æœ€é«˜
    PRO: 5,         // ä¸“ä¸šç‰ˆä¸­ç­‰
    FREE: 1         // å…è´¹ç‰ˆæœ€ä½
  },

  // è¶…æ—¶é…ç½®
  timeouts: {
    readability: 60000,      // æ˜“è¯»æ€§è¯„åˆ†ï¼š1åˆ†é’Ÿ
    refinement: 120000,      // å†…å®¹æç‚¼ï¼š2åˆ†é’Ÿ
    expansion: 300000,       // å†…å®¹æ‰©å±•ï¼š5åˆ†é’Ÿ
    total: 600000            // æ€»è¶…æ—¶ï¼š10åˆ†é’Ÿ
  },

  // é‡è¯•é…ç½®
  retry: {
    maxAttempts: 3,
    backoffType: 'exponential',
    backoffDelay: 2000
  }
}
```

## äºŒã€Workerå®ç°

### 2.1 WorkeråŸºç¡€é…ç½®

```typescript
// src/modules/analysis/workers/analyze.worker.ts
import { Worker, Job, WorkerOptions } from 'bullmq'
import { InjectRedis } from '@nestjs-modules/ioredis'
import Redis from 'ioredis'
import { Logger } from '@nestjs/common'
import { AnalyzeJobData, ANALYSIS_QUEUE_NAME } from '../queues/analysis.queue'
import { AiService } from '@/modules/ai/ai.service'
import { SearchService } from '@/modules/search/search.service'
import { PrismaService } from '@/database/prisma.service'

export class AnalyzeWorker {
  private worker: Worker<AnalyzeJobData>
  private logger = new Logger(AnalyzeWorker.name)

  constructor(
    @InjectRedis() private redis: Redis,
    private aiService: AiService,
    private searchService: SearchService,
    private prisma: PrismaService
  ) {
    const options: WorkerOptions = {
      connection: {
        host: process.env.REDIS_HOST,
        port: parseInt(process.env.REDIS_PORT),
        password: process.env.REDIS_PASSWORD
      },
      concurrency: parseInt(process.env.WORKER_CONCURRENCY || '5'),
      limiter: {
        max: 100, // æ¯åˆ†é’Ÿæœ€å¤šå¤„ç†100ä¸ªä»»åŠ¡
        duration: 60000
      }
    }

    this.worker = new Worker(
      ANALYSIS_QUEUE_NAME,
      async (job: Job<AnalyzeJobData>) => this.process(job),
      options
    )

    this.setupEventListeners()
  }

  private setupEventListeners() {
    // ä»»åŠ¡å®Œæˆ
    this.worker.on('completed', (job: Job) => {
      this.logger.log(`Job ${job.id} completed`)
    })

    // ä»»åŠ¡å¤±è´¥
    this.worker.on('failed', (job: Job | undefined, error: Error) => {
      this.logger.error(
        `Job ${job?.id} failed: ${error.message}`,
        error.stack
      )
    })

    // ä»»åŠ¡è¿›åº¦
    this.worker.on('progress', (job: Job, progress: number) => {
      this.logger.log(`Job ${job.id} progress: ${progress}%`)
    })
  }

  async process(job: Job<AnalyzeJobData>) {
    const { userId, analysisId, content, title, enableExpansion } = job.data

    try {
      // æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
      await this.updateAnalysisStatus(analysisId, 'PROCESSING')

      // æ­¥éª¤1: æ˜“è¯»æ€§è¯„åˆ† (20%)
      job.updateProgress(20)
      const readabilityScore = await this.assessReadability(content)
      await this.updateAnalysisProgress(analysisId, 20, 'æ­£åœ¨è¯„ä¼°æ˜“è¯»æ€§...')

      // æ­¥éª¤2: å†…å®¹æç‚¼ (40%)
      job.updateProgress(40)
      const refinedContent = await this.refineContent(content)
      await this.updateAnalysisProgress(analysisId, 40, 'æ­£åœ¨æç‚¼å†…å®¹...')

      // æ­¥éª¤3: æ™ºèƒ½æ‰©å±•ï¼ˆå¯é€‰ï¼‰(60-90%)
      let expansions = null
      let sources = []

      if (enableExpansion) {
        await this.updateAnalysisProgress(analysisId, 60, 'æ­£åœ¨åˆ†ææ‰©å±•ç‚¹...')

        // AIåˆ†æéœ€è¦æ‰©å±•çš„ç‚¹
        const keyPoints = await this.identifyKeyPoints(content, refinedContent)

        expansions = []
        for (let i = 0; i < keyPoints.length; i++) {
          const point = keyPoints[i]

          // æœç´¢ç›¸å…³èµ„æ–™
          await this.updateAnalysisProgress(
            analysisId,
            60 + (i / keyPoints.length) * 30,
            `æ­£åœ¨æ‰©å±•: ${point.substring(0, 20)}...`
          )

          const searchResults = await this.searchService.search(point, {
            limit: 3
          })

          // åŸºäºæœç´¢ç»“æœæ‰©å±•
          const expansion = await this.aiService.expand(point, searchResults)

          expansions.push({
            keyPoint: point,
            expansion: expansion.content,
            sources: searchResults.map(r => r.url)
          })

          sources.push(...searchResults)
        }
      }

      // æ­¥éª¤4: ä¿å­˜ç»“æœ (100%)
      job.updateProgress(100)
      await this.saveResult(analysisId, {
        readabilityScore,
        processedContent: refinedContent,
        expansions,
        sources,
        status: 'COMPLETED'
      })

      await this.updateAnalysisProgress(analysisId, 100, 'è§£æå®Œæˆ')

      this.logger.log(`Analysis ${analysisId} completed successfully`)

      return { success: true }
    } catch (error) {
      this.logger.error(
        `Analysis ${analysisId} failed: ${error.message}`,
        error.stack
      )

      // ä¿å­˜é”™è¯¯ä¿¡æ¯
      await this.prisma.analysis.update({
        where: { id: analysisId },
        data: {
          status: 'FAILED',
          errorMessage: error.message
        }
      })

      throw error
    }
  }

  // æ˜“è¯»æ€§è¯„åˆ†
  private async assessReadability(content: string) {
    return this.aiService.assessReadability(content, {
      timeout: QUEUE_CONFIG.timeouts.readability
    })
  }

  // å†…å®¹æç‚¼
  private async refineContent(content: string) {
    return this.aiService.refineContent(content, {
      timeout: QUEUE_CONFIG.timeouts.refinement
    })
  }

  // è¯†åˆ«å…³é”®ç‚¹
  private async identifyKeyPoints(
    originalContent: string,
    refinedContent: string
  ): Promise<string[]> {
    return this.aiService.identifyKeyPoints(
      originalContent,
      refinedContent
    )
  }

  // ä¿å­˜ç»“æœ
  private async saveResult(
    analysisId: string,
    data: {
      readabilityScore: any
      processedContent: string
      expansions: any
      sources: any[]
      status: string
    }
  ) {
    await this.prisma.analysis.update({
      where: { id: analysisId },
      data: {
        readabilityScore: data.readabilityScore.overall,
        readabilityDetail: data.readabilityScore,
        processedContent: data.processedContent,
        expansions: data.expansions,
        sources: data.sources,
        status: data.status as any
      }
    })
  }

  // æ›´æ–°è§£æçŠ¶æ€
  private async updateAnalysisStatus(
    analysisId: string,
    status: 'PROCESSING' | 'COMPLETED' | 'FAILED'
  ) {
    await this.prisma.analysis.update({
      where: { id: analysisId },
      data: { status }
    })
  }

  // æ›´æ–°è§£æè¿›åº¦
  private async updateAnalysisProgress(
    analysisId: string,
    progress: number,
    message: string
  ) {
    // æ›´æ–°Redis
    await this.redis.setex(
      `analysis:progress:${analysisId}`,
      3600,
      JSON.stringify({ progress, message })
    )

    // é€šè¿‡WebSocketæ¨é€
    // WebSocketæœåŠ¡ä¼šç›‘å¬Redisçš„publishäº‹ä»¶
    await this.redis.publish(
      `analysis:progress:${analysisId}`,
      JSON.stringify({ progress, message })
    )
  }

  // ä¼˜é›…å…³é—­
  async close() {
    await this.worker.close()
  }
}
```

### 2.2 Workeræ¨¡å—é›†æˆ

```typescript
// src/modules/analysis/analysis.module.ts
import { Module } from '@nestjs/common'
import { BullModule } from '@nestjs/bullmq'
import { AnalysisController } from './analysis.controller'
import { AnalysisService } from './analysis.service'
import { AnalyzeWorker } from './workers/analyze.worker'
import { AnalysisQueue } from './queues/analysis.queue'
import { AiModule } from '@/modules/ai/ai.module'
import { SearchModule } from '@/modules/search/search.module'

@Module({
  imports: [
    BullModule.forRoot({
      connection: {
        host: process.env.REDIS_HOST,
        port: parseInt(process.env.REDIS_PORT),
        password: process.env.REDIS_PASSWORD
      }
    }),
    BullModule.registerQueue({
      name: 'analysis'
    }),
    AiModule,
    SearchModule
  ],
  controllers: [AnalysisController],
  providers: [AnalysisService, AnalyzeWorker, AnalysisQueue],
  exports: [AnalysisService, AnalysisQueue]
})
export class AnalysisModule {}
```

## ä¸‰ã€ä»»åŠ¡ä¼˜å…ˆçº§ä¸è°ƒåº¦

### 3.1 åŠ¨æ€ä¼˜å…ˆçº§åˆ†é…

```typescript
// src/modules/analysis/analysis.service.ts
import { Membership } from '@prisma/client'
import { QUEUE_CONFIG } from './queues/queue.config'

@Injectable()
export class AnalysisService {
  constructor(private analysisQueue: AnalysisQueue) {}

  async createAnalysis(userId: string, dto: AnalyzeDto, user: User) {
    // 1. æ£€æŸ¥å¹¶å‘é™åˆ¶
    await this.checkConcurrencyLimit(userId, user.membership)

    // 2. åˆ›å»ºåˆ†æè®°å½•
    const analysis = await this.prisma.analysis.create({
      data: {
        userId,
        title: dto.title,
        originalContent: dto.content,
        status: 'PENDING'
      }
    })

    // 3. è®¡ç®—ä¼˜å…ˆçº§
    const priority = this.calculatePriority(user.membership)

    // 4. æ·»åŠ åˆ°é˜Ÿåˆ—
    await this.analysisQueue.addAnalyzeJob({
      userId,
      analysisId: analysis.id,
      content: dto.content,
      title: dto.title,
      enableExpansion: dto.enableExpansion,
      priority
    })

    return {
      taskId: analysis.id,
      status: 'PROCESSING',
      estimatedTime: this.estimateTime(dto.enableExpansion)
    }
  }

  private calculatePriority(membership: Membership): number {
    switch (membership) {
      case Membership.ENTERPRISE:
        return QUEUE_CONFIG.priority.ENTERPRISE
      case Membership.PRO:
        return QUEUE_CONFIG.priority.PRO
      case Membership.FREE:
      default:
        return QUEUE_CONFIG.priority.FREE
    }
  }

  // æ£€æŸ¥å¹¶å‘é™åˆ¶
  private async checkConcurrencyLimit(
    userId: string,
    membership: Membership
  ) {
    const maxConcurrent = QUEUE_CONFIG.concurrency[membership]

    const activeCount = await this.prisma.analysis.count({
      where: {
        userId,
        status: {
          in: ['PENDING', 'PROCESSING']
        }
      }
    })

    if (activeCount >= maxConcurrent) {
      throw new ConflictException(
        `å½“å‰æœ‰${activeCount}ä¸ªä»»åŠ¡æ­£åœ¨å¤„ç†ï¼Œå·²è¾¾ä¼šå‘˜ä¸Šé™(${maxConcurrent})`
      )
    }
  }

  // é¢„ä¼°å¤„ç†æ—¶é—´
  private estimateTime(enableExpansion: boolean): number {
    const baseTime = 30 // åŸºç¡€æ—¶é—´30ç§’
    const expansionTime = enableExpansion ? 90 : 0 // æ‰©å±•éœ€è¦é¢å¤–90ç§’
    return baseTime + expansionTime
  }
}
```

### 3.2 å»¶è¿Ÿä»»åŠ¡

```typescript
// åœ¨ç‰¹å®šæ—¶é—´æ‰§è¡Œä»»åŠ¡
async scheduleAnalysis(
  userId: string,
  dto: AnalyzeDto,
  scheduledAt: Date
) {
  const analysis = await this.prisma.analysis.create({
    data: {
      userId,
      title: dto.title,
      originalContent: dto.content,
      status: 'PENDING'
    }
  })

  const delay = scheduledAt.getTime() - Date.now()

  await this.analysisQueue.queue.add('analyze-article', {
    userId,
    analysisId: analysis.id,
    content: dto.content,
    enableExpansion: dto.enableExpansion,
    priority: 5
  }, {
    delay: delay > 0 ? delay : 0
  })

  return { taskId: analysis.id, scheduledAt }
}
```

## å››ã€è¿›åº¦è¿½è¸ª

### 4.1 WebSocketå®æ—¶æ¨é€

```typescript
// src/modules/websocket/websocket.gateway.ts
import {
  WebSocketGateway,
  WebSocketServer,
  SubscribeMessage,
  OnGatewayConnection,
  OnGatewayDisconnect
} from '@nestjs/websockets'
import { Server, Socket } from 'socket.io'
import { InjectRedis } from '@nestjs-modules/ioredis'
import Redis from 'ioredis'
import { UseGuards } from '@nestjs/common'

@WebSocketGateway({
  cors: {
    origin: process.env.FRONTEND_URL,
    credentials: true
  }
})
export class AnalysisGateway implements OnGatewayConnection, OnGatewayDisconnect {
  @WebSocketServer()
  server: Server

  private userSocketMap = new Map<string, Set<string>>()

  constructor(@InjectRedis() private redis: Redis) {
    this.subscribeToProgress()
  }

  handleConnection(client: Socket) {
    const userId = this.extractUserId(client)
    if (!userId) {
      client.disconnect()
      return
    }

    // è®°å½•ç”¨æˆ·è¿æ¥
    if (!this.userSocketMap.has(userId)) {
      this.userSocketMap.set(userId, new Set())
    }
    this.userSocketMap.get(userId)!.add(client.id)

    console.log(`User ${userId} connected with socket ${client.id}`)
  }

  handleDisconnect(client: Socket) {
    const userId = this.extractUserId(client)
    if (userId) {
      this.userSocketMap.get(userId)?.delete(client.id)
    }
  }

  // è®¢é˜…Redisè¿›åº¦æ›´æ–°
  private subscribeToProgress() {
    const subscriber = this.redis.duplicate()

    subscriber.psubscribe('analysis:progress:*', (err) => {
      if (err) {
        console.error('Failed to subscribe to progress updates:', err)
      }
    })

    subscriber.on('pmessage', (pattern, channel, message) => {
      const analysisId = channel.split(':')[2]
      const data = JSON.parse(message)

      this.broadcastProgress(analysisId, data)
    })
  }

  // å¹¿æ’­è¿›åº¦ç»™æ‰€æœ‰ç›¸å…³ç”¨æˆ·
  private broadcastProgress(analysisId: string, data: any) {
    this.server.emit(`analysis:${analysisId}:progress`, data)
  }

  // å®¢æˆ·ç«¯è®¢é˜…ç‰¹å®šä»»åŠ¡çš„è¿›åº¦
  @SubscribeMessage('subscribe:analysis')
  handleSubscribe(client: Socket, analysisId: string) {
    const room = `analysis:${analysisId}`
    client.join(room)

    // å‘é€å½“å‰è¿›åº¦
    this.redis.get(`analysis:progress:${analysisId}`).then((progress) => {
      if (progress) {
        client.emit(`analysis:${analysisId}:progress`, JSON.parse(progress))
      }
    })
  }

  // å®¢æˆ·ç«¯å–æ¶ˆè®¢é˜…
  @SubscribeMessage('unsubscribe:analysis')
  handleUnsubscribe(client: Socket, analysisId: string) {
    const room = `analysis:${analysisId}`
    client.leave(room)
  }

  private extractUserId(client: Socket): string | null {
    // ä»æ¡æ‰‹æˆ–tokenä¸­æå–userId
    const token = client.handshake.auth.token
    // éªŒè¯tokenå¹¶è¿”å›userId
    return null // ç®€åŒ–ç¤ºä¾‹
  }
}
```

### 4.2 å‰ç«¯é›†æˆ

```typescript
// frontend/src/api/websocket.ts
import { io, Socket } from 'socket.io-client'

class WebSocketService {
  private socket: Socket | null = null

  connect(token: string) {
    this.socket = io(process.env.VITE_WS_URL, {
      auth: { token },
      transports: ['websocket']
    })

    this.socket.on('connect', () => {
      console.log('WebSocket connected')
    })

    this.socket.on('disconnect', () => {
      console.log('WebSocket disconnected')
    })
  }

  subscribeToAnalysis(
    analysisId: string,
    onProgress: (data: { progress: number; message: string }) => void
  ) {
    if (!this.socket) {
      throw new Error('WebSocket not connected')
    }

    this.socket.emit('subscribe:analysis', analysisId)
    this.socket.on(`analysis:${analysisId}:progress`, onProgress)
  }

  unsubscribeFromAnalysis(analysisId: string) {
    if (this.socket) {
      this.socket.emit('unsubscribe:analysis', analysisId)
      this.socket.removeAllListeners(`analysis:${analysisId}:progress`)
    }
  }

  disconnect() {
    if (this.socket) {
      this.socket.disconnect()
      this.socket = null
    }
  }
}

export const wsService = new WebSocketService()
```

## äº”ã€é”™è¯¯å¤„ç†ä¸é‡è¯•

### 5.1 é‡è¯•ç­–ç•¥

```typescript
// æ™ºèƒ½é‡è¯•é…ç½®
const RETRY_STRATEGIES = {
  // AIæœåŠ¡é”™è¯¯ï¼šé‡è¯•
  AI_SERVICE_ERROR: {
    attempts: 3,
    backoff: {
      type: 'exponential',
      delay: 2000
    }
  },

  // ç½‘ç»œè¶…æ—¶ï¼šé‡è¯•
  TIMEOUT_ERROR: {
    attempts: 2,
    backoff: {
      type: 'fixed',
      delay: 5000
    }
  },

  // å†…å®¹è¿‡é•¿ï¼šä¸é‡è¯•
  CONTENT_TOO_LONG: {
    attempts: 1
  },

  // ä½™é¢ä¸è¶³ï¼šä¸é‡è¯•
  INSUFFICIENT_BALANCE: {
    attempts: 1
  }
}

// åœ¨Workerä¸­ä½¿ç”¨
async process(job: Job<AnalyzeJobData>) {
  try {
    // å¤„ç†é€»è¾‘
  } catch (error) {
    const strategy = this.getRetryStrategy(error)

    if (strategy.attempts > 1) {
      // æ›´æ–°é‡è¯•é…ç½®
      job.opts.attempts = strategy.attempts
      job.opts.backoff = strategy.backoff
    }

    throw error
  }
}

private getRetryStrategy(error: Error) {
  if (error.message.includes('timeout')) {
    return RETRY_STRATEGIES.TIMEOUT_ERROR
  }

  if (error.message.includes('content too long')) {
    return RETRY_STRATEGIES.CONTENT_TOO_LONG
  }

  // é»˜è®¤ç­–ç•¥
  return RETRY_STRATEGIES.AI_SERVICE_ERROR
}
```

### 5.2 æ­»ä¿¡é˜Ÿåˆ—

```typescript
// åˆ›å»ºæ­»ä¿¡é˜Ÿåˆ—å¤„ç†å¤±è´¥ä»»åŠ¡
export class DeadLetterQueue {
  private dlq: Queue

  constructor(redis: Redis) {
    this.dlq = new Queue('analysis:dlq', {
      connection: redis
    })
  }

  async addFailedJob(job: Job<AnalyzeJobData>, error: Error) {
    await this.dlq.add('failed-analysis', {
      originalJobData: job.data,
      error: {
        message: error.message,
        stack: error.stack,
        timestamp: new Date()
      },
      failedAttempts: job.attemptsMade,
      timestamp: new Date()
    })
  }

  // é‡è¯•æ­»ä¿¡é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
  async retry(jobId: string) {
    const job = await this.dlq.getJob(jobId)
    if (job) {
      const { originalJobData } = job.data
      await this.analysisQueue.addAnalyzeJob(originalJobData)
      await job.remove()
    }
  }
}
```

## å…­ã€ç›‘æ§é¢æ¿

### 6.1 Bull Boardé›†æˆ

```typescript
// src/modules/queue/ui/queue-ui.module.ts
import { Module } from '@nestjs/common'
import { BullBoardAdapter } from '@bull-board/api/bullmqAdapter'
import { ExpressAdapter } from '@bull-board/express'
import { createBullBoard } from '@bull-board/api'

const serverAdapter = new ExpressAdapter()
serverAdapter.setBasePath('/admin/queues')

createBullBoard({
  queues: [
    new BullBoardAdapter(analysisQueue.queue)
  ],
  serverAdapter
})

@Module({
  imports: [],
  providers: [],
  exports: []
})
export class QueueUiModule {}

// åœ¨main.tsä¸­
import { queueUiAdapter } from './modules/queue/ui/queue-ui.module'

async function bootstrap() {
  const app = await NestFactory.create(AppModule)

  // æŒ‚è½½Bull Board
  app.use('/admin/queues', queueUiAdapter.getRouter())

  // ä¿æŠ¤ç®¡ç†ç•Œé¢
  // æ·»åŠ è®¤è¯ä¸­é—´ä»¶...

  await app.listen(3000)
}
```

### 6.2 è‡ªå®šä¹‰ç›‘æ§æŒ‡æ ‡

```typescript
// src/modules/queue/metrics/queue-metrics.service.ts
import { Injectable } from '@nestjs/common'
import { AnalysisQueue } from '../queues/analysis.queue'

@Injectable()
export class QueueMetricsService {
  constructor(private analysisQueue: AnalysisQueue) {}

  async getMetrics() {
    const stats = await this.analysisQueue.getQueueStats()

    // è·å–é˜Ÿåˆ—é€Ÿç‡
    const rates = await this.getProcessingRates()

    // è·å–å¹³å‡å¤„ç†æ—¶é—´
    const avgTime = await this.getAverageProcessingTime()

    return {
      ...stats,
      rates,
      avgTime,
      timestamp: new Date()
    }
  }

  private async getProcessingRates() {
    // è®¡ç®—æ¯åˆ†é’Ÿå¤„ç†ä»»åŠ¡æ•°
    const completed = await this.analysisQueue.queue.getCompletedCount()
    const timeWindow = 60 // ç§’

    // ä½¿ç”¨Redisè®¡æ•°å™¨
    // å®é™…å®ç°éœ€è¦æ›´å¤æ‚çš„é€»è¾‘
    return {
      perMinute: Math.floor(completed / timeWindow),
      perHour: Math.floor((completed / timeWindow) * 60)
    }
  }

  private async getAverageProcessingTime() {
    const jobs = await this.analysisQueue.queue.getCompleted(0, 100)

    if (jobs.length === 0) return 0

    const totalTime = jobs.reduce((sum, job) => {
      return sum + (job.processedOn! - job.timestamp)
    }, 0)

    return Math.floor(totalTime / jobs.length)
  }

  // è·å–å¥åº·çŠ¶æ€
  async getHealthStatus() {
    const stats = await this.analysisQueue.getQueueStats()

    // åˆ¤æ–­å¥åº·çŠ¶æ€
    const health = {
      status: 'healthy' as 'healthy' | 'warning' | 'critical',
      issues: [] as string[]
    }

    // å¤±è´¥ç‡è¿‡é«˜
    const failureRate = stats.failed / (stats.completed + stats.failed)
    if (failureRate > 0.1) {
      health.status = 'warning'
      health.issues.push('å¤±è´¥ç‡è¿‡é«˜')
    }

    // ç­‰å¾…é˜Ÿåˆ—è¿‡é•¿
    if (stats.waiting > 1000) {
      health.status = 'warning'
      health.issues.push('ç­‰å¾…é˜Ÿåˆ—è¿‡é•¿')
    }

    // å¤„ç†åœæ»
    if (stats.active === 0 && stats.waiting > 0) {
      health.status = 'critical'
      health.issues.push('Workerå¤„ç†åœæ»')
    }

    return health
  }
}
```

## ä¸ƒã€æ€§èƒ½ä¼˜åŒ–

### 7.1 æ‰¹å¤„ç†ä¼˜åŒ–

```typescript
// æ‰¹é‡å¤„ç†å¤šä¸ªåˆ†æä»»åŠ¡
async batchAnalyze(
  userId: string,
  articles: Array<{ content: string; title?: string }>,
  user: User
) {
  // æ£€æŸ¥ä¼šå‘˜æ‰¹é‡å¤„ç†æƒé™
  const maxBatchSize = this.getMaxBatchSize(user.membership)
  if (articles.length > maxBatchSize) {
    throw new BadRequestException(
      `æ‰¹é‡ä»»åŠ¡æœ€å¤š${maxBatchSize}ç¯‡ï¼Œå½“å‰${articles.length}ç¯‡`
    )
  }

  const analyses = await Promise.all(
    articles.map(async (article) => {
      const analysis = await this.prisma.analysis.create({
        data: {
          userId,
          title: article.title,
          originalContent: article.content,
          status: 'PENDING'
        }
      })

      // æ‰¹é‡æ·»åŠ åˆ°é˜Ÿåˆ—
      await this.analysisQueue.addAnalyzeJob({
        userId,
        analysisId: analysis.id,
        content: article.content,
        title: article.title,
        enableExpansion: false, // æ‰¹é‡ä»»åŠ¡é»˜è®¤ä¸æ‰©å±•
        priority: this.calculatePriority(user.membership)
      })

      return analysis
    })
  )

  return {
    batchId: uuid(),
    taskIds: analyses.map(a => a.id),
    total: analyses.length,
    status: 'PROCESSING'
  }
}

private getMaxBatchSize(membership: Membership): number {
  switch (membership) {
    case Membership.ENTERPRISE: return 20
    case Membership.PRO: return 10
    case Membership.FREE: return 3
  }
}
```

### 7.2 è¿æ¥æ± ä¼˜åŒ–

```typescript
// Redisè¿æ¥æ± é…ç½®
const redisConfig = {
  host: process.env.REDIS_HOST,
  port: parseInt(process.env.REDIS_PORT),
  password: process.env.REDIS_PASSWORD,
  maxRetriesPerRequest: 3,
  retryStrategy: (times: number) => {
    const delay = Math.min(times * 50, 2000)
    return delay
  },
  enableReadyCheck: true,
  enableOfflineQueue: true,
  lazyConnect: false
}

// Workerè¿æ¥æ± 
const workerConfig = {
  connection: redisConfig,
  concurrency: parseInt(process.env.WORKER_CONCURRENCY || '5'),
  maxStalledCount: 1, // æœ€å¤§åœæ»ä»»åŠ¡æ•°
  stalledInterval: 30000 // æ£€æŸ¥é—´éš”30ç§’
}
```

### 7.3 ç¼“å­˜ä¼˜åŒ–

```typescript
// ç¼“å­˜AIå“åº”ç»“æœ
@Injectable()
export class CacheService {
  constructor(@InjectRedis() private redis: Redis) {}

  async getCachedAnalysis(contentHash: string) {
    const cached = await this.redis.get(`analysis:cache:${contentHash}`)
    return cached ? JSON.parse(cached) : null
  }

  async setCachedAnalysis(
    contentHash: string,
    result: any,
    ttl: number = 7 * 24 * 3600 // 7å¤©
  ) {
    await this.redis.setex(
      `analysis:cache:${contentHash}`,
      ttl,
      JSON.stringify(result)
    )
  }

  // ç”Ÿæˆå†…å®¹å“ˆå¸Œ
  hashContent(content: string): string {
    return crypto.createHash('sha256').update(content).digest('hex')
  }
}

// åœ¨Workerä¸­ä½¿ç”¨
async process(job: Job<AnalyzeJobData>) {
  const { content } = job.data
  const contentHash = this.cacheService.hashContent(content)

  // æ£€æŸ¥ç¼“å­˜
  const cached = await this.cacheService.getCachedAnalysis(contentHash)
  if (cached) {
    // ä½¿ç”¨ç¼“å­˜ç»“æœ
    await this.saveResult(job.data.analysisId, cached)
    return { success: true, cached: true }
  }

  // æ‰§è¡Œåˆ†æ
  const result = await this.performAnalysis(content)

  // ç¼“å­˜ç»“æœ
  await this.cacheService.setCachedAnalysis(contentHash, result)

  return { success: true, cached: false }
}
```

## å…«ã€æµ‹è¯•

### 8.1 å•å…ƒæµ‹è¯•

```typescript
// src/modules/analysis/workers/analyze.worker.spec.ts
import { Test, TestingModule } from '@nestjs/testing'
import { AnalyzeWorker } from './analyze.worker'
import { QUEUE_CONFIG } from '../queues/queue.config'

describe('AnalyzeWorker', () => {
  let worker: AnalyzeWorker
  let mockAiService: Partial<AiService>
  let mockPrisma: Partial<PrismaService>

  beforeEach(async () => {
    mockAiService = {
      assessReadability: jest.fn(),
      refineContent: jest.fn(),
      identifyKeyPoints: jest.fn(),
      expand: jest.fn()
    }

    mockPrisma = {
      analysis: {
        update: jest.fn(),
        findUnique: jest.fn()
      }
    }

    const module: TestingModule = await Test.createTestingModule({
      providers: [
        AnalyzeWorker,
        {
          provide: AiService,
          useValue: mockAiService
        },
        {
          provide: PrismaService,
          useValue: mockPrisma
        },
        {
          provide: 'REDIS',
          useValue: {
            duplicate: jest.fn(() => ({
              psubscribe: jest.fn(),
              on: jest.fn()
            }))
          }
        }
      ]
    }).compile()

    worker = module.get<AnalyzeWorker>(AnalyzeWorker)
  })

  it('should process analysis job successfully', async () => {
    const mockJob = {
      id: 'test-job-id',
      data: {
        userId: 'user-1',
        analysisId: 'analysis-1',
        content: 'Test content',
        enableExpansion: false,
        priority: 5
      },
      updateProgress: jest.fn()
    } as any

    mockAiService.assessReadability.mockResolvedValue({
      overall: 3,
      vocabulary: 3,
      sentence: 3,
      logic: 3
    })

    mockAiService.refineContent.mockResolvedValue('Refined content')

    const result = await worker.process(mockJob)

    expect(result.success).toBe(true)
    expect(mockAiService.assessReadability).toHaveBeenCalledWith('Test content')
    expect(mockAiService.refineContent).toHaveBeenCalledWith('Test content')
  })

  it('should handle AI service errors and retry', async () => {
    const mockJob = {
      id: 'test-job-id',
      data: {
        userId: 'user-1',
        analysisId: 'analysis-1',
        content: 'Test content',
        enableExpansion: false,
        priority: 5
      },
      updateProgress: jest.fn(),
      opts: {
        attempts: 3
      }
    } as any

    mockAiService.assessReadability.mockRejectedValue(
      new Error('AI service timeout')
    )

    await expect(worker.process(mockJob)).rejects.toThrow('AI service timeout')
  })
})
```

### 8.2 é›†æˆæµ‹è¯•

```typescript
// test/queue.e2e-spec.ts
describe('Queue Integration (e2e)', () => {
  let app: INestApplication
  let analysisQueue: AnalysisQueue

  beforeAll(async () => {
    const moduleFixture: TestingModule = await Test.createTestingModule({
      imports: [AppModule]
    }).compile()

    app = moduleFixture.createNestApplication()
    await app.init()

    analysisQueue = app.get<AnalysisQueue>(AnalysisQueue)
  })

  describe('Analysis Queue', () => {
    it('should add job to queue', async () => {
      const jobData = {
        userId: 'test-user',
        analysisId: 'test-analysis',
        content: 'Test content',
        enableExpansion: false,
        priority: 5
      }

      const job = await analysisQueue.addAnalyzeJob(jobData)

      expect(job.id).toBeDefined()
      expect(job.data).toEqual(jobData)
    })

    it('should process job with worker', async (done) => {
      const jobData = {
        userId: 'test-user',
        analysisId: 'test-analysis-2',
        content: 'Test content for processing',
        enableExpansion: false,
        priority: 5
      }

      const job = await analysisQueue.addAnalyzeJob(jobData)

      // ç­‰å¾…ä»»åŠ¡å®Œæˆ
      job.waitUntilFinished(analysisQueue.queue).then((result) => {
        expect(result.success).toBe(true)
        done()
      })
    }, 30000)
  })

  afterAll(async () => {
    await app.close()
  })
})
```

## ä¹ã€éƒ¨ç½²ä¸è¿ç»´

### 9.1 Dockeré…ç½®

```dockerfile
# Dockerfile
FROM node:20-alpine

WORKDIR /app

COPY package*.json ./
RUN npm ci --only=production

COPY . .
RUN npm run build

# Workeræ¨¡å¼
CMD ["node", "dist/main.js", "--mode", "worker"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  api:
    build: .
    command: node dist/main.js --mode api
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - WORKER_MODE=false
    depends_on:
      - redis
      - db

  worker:
    build: .
    command: node dist/main.js --mode worker
    environment:
      - NODE_ENV=production
      - WORKER_MODE=true
      - WORKER_CONCURRENCY=10
    deploy:
      replicas: 3
    depends_on:
      - redis
      - api

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

volumes:
  redis_data:
```

### 9.2 ç›‘æ§å‘Šè­¦

```typescript
// src/modules/queue/alerting/alerting.service.ts
@Injectable()
export class AlertingService {
  constructor(
    private queueMetrics: QueueMetricsService,
    private notificationService: NotificationService
  ) {
    this.startMonitoring()
  }

  private startMonitoring() {
    // æ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    setInterval(async () => {
      const health = await this.queueMetrics.getHealthStatus()

      if (health.status !== 'healthy') {
        await this.sendAlert(health)
      }
    }, 5 * 60 * 1000)
  }

  private async sendAlert(health: any) {
    const message = `
      é˜Ÿåˆ—å‘Šè­¦ âš ï¸
      çŠ¶æ€: ${health.status}
      é—®é¢˜:
      ${health.issues.map(i => `- ${i}`).join('\n')}
      æ—¶é—´: ${new Date().toISOString()}
    `

    // å‘é€é‚®ä»¶ã€é’‰é’‰ã€Slackç­‰
    await this.notificationService.send({
      channel: 'slack',
      message
    })
  }
}
```

### 9.3 æ—¥å¿—åˆ†æ

```typescript
// ç»“æ„åŒ–æ—¥å¿—
this.logger.log({
  message: 'Job processing started',
  jobId: job.id,
  userId: job.data.userId,
  priority: job.data.priority,
  timestamp: new Date()
})

// ä½¿ç”¨Winstonè®°å½•åˆ°æ–‡ä»¶
const logger = winston.createLogger({
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.File({
      filename: 'logs/queue.log',
      maxsize: 10 * 1024 * 1024, // 10MB
      maxFiles: 10
    })
  ]
})
```

## åã€æœ€ä½³å®è·µ

### 10.1 ä»»åŠ¡è®¾è®¡åŸåˆ™

1. **å¹‚ç­‰æ€§**ï¼šä»»åŠ¡å¯ä»¥å®‰å…¨åœ°é‡å¤æ‰§è¡Œ
2. **åŸå­æ€§**ï¼šä»»åŠ¡è¦ä¹ˆå®Œå…¨æˆåŠŸï¼Œè¦ä¹ˆå®Œå…¨å¤±è´¥
3. **è¶…æ—¶æ§åˆ¶**ï¼šè®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
4. **é”™è¯¯éš”ç¦»**ï¼šå•ä¸ªä»»åŠ¡å¤±è´¥ä¸å½±å“å…¶ä»–ä»»åŠ¡
5. **è¿›åº¦åé¦ˆ**ï¼šå®šæœŸæ›´æ–°ä»»åŠ¡è¿›åº¦

### 10.2 æ€§èƒ½è°ƒä¼˜å»ºè®®

```typescript
// æ ¹æ®è´Ÿè½½åŠ¨æ€è°ƒæ•´Workeræ•°é‡
async function autoScaleWorkers() {
  const stats = await analysisQueue.getQueueStats()

  // ç­‰å¾…é˜Ÿåˆ—è¿‡é•¿ï¼Œå¢åŠ Worker
  if (stats.waiting > 100) {
    await scaleUpWorkers()
  }

  // ç©ºé—²æ—¶å‡å°‘Worker
  if (stats.active === 0 && stats.waiting === 0) {
    await scaleDownWorkers()
  }
}

// ä½¿ç”¨Redis Streamså¤„ç†é«˜å¹¶å‘
// å¯¹äºæé«˜å¹¶å‘åœºæ™¯ï¼Œè€ƒè™‘ä½¿ç”¨Kafkaæˆ–RabbitMQ
```

### 10.3 æ•…éšœæ¢å¤

```typescript
// è‡ªåŠ¨é‡å¯Worker
process.on('uncaughtException', async (error) => {
  logger.error('Uncaught Exception:', error)
  await cleanup()
  process.exit(1)
})

process.on('SIGTERM', async () => {
  logger.info('SIGTERM received, shutting down gracefully')
  await worker.close()
  process.exit(0)
})

// å®šæœŸå¤‡ä»½é˜Ÿåˆ—çŠ¶æ€
async function backupQueueState() {
  const jobs = await analysisQueue.queue.getRepeatableJobs()
  await redis.set(
    'queue:backup',
    JSON.stringify(jobs),
    'EX',
    86400
  )
}
```

## ç›¸å…³æ–‡æ¡£

- [ç³»ç»Ÿæ¶æ„](/guide/architecture)
- [è®¤è¯é‰´æƒ](/guide/authentication)
- [APIæ–‡æ¡£](/guide/api)
- [æ•°æ®åº“è®¾è®¡](/guide/database)
